<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Martin Jambon, July 2017" />
  <title>Real-time decomposition of a signal into a sum of responses to labeled events</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../blog.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Language" content="en">
</head>
<body>
<header id="title-block-header">
<h1 class="title">Real-time decomposition of a signal into a sum of responses to labeled events</h1>
<p class="author">Martin Jambon, July 2017</p>
</header>
<nav id="TOC">
<ul>
<li><a href="#motivation-in-the-context-of-artificial-general-intelligence"><span class="toc-section-number">1</span> Motivation in the context of artificial general intelligence</a></li>
<li><a href="#general-design-contraints"><span class="toc-section-number">2</span> General design contraints</a><ul>
<li><a href="#independence-from-context"><span class="toc-section-number">2.1</span> Independence from context</a></li>
<li><a href="#effects-can-be-delayed"><span class="toc-section-number">2.2</span> Effects can be delayed</a></li>
<li><a href="#overlapping-effects"><span class="toc-section-number">2.3</span> Overlapping effects</a></li>
<li><a href="#incremental-learning"><span class="toc-section-number">2.4</span> Incremental learning</a></li>
<li><a href="#adaptation"><span class="toc-section-number">2.5</span> Adaptation</a></li>
</ul></li>
<li><a href="#notations"><span class="toc-section-number">3</span> Notations</a></li>
<li><a href="#solution"><span class="toc-section-number">4</span> Solution</a><ul>
<li><a href="#outline"><span class="toc-section-number">4.1</span> Outline</a></li>
<li><a href="#description"><span class="toc-section-number">4.2</span> Description</a><ul>
<li><a href="#prediction-and-update"><span class="toc-section-number">4.2.1</span> Prediction and update</a></li>
<li><a href="#details-and-refinements"><span class="toc-section-number">4.2.2</span> Details and refinements</a></li>
</ul></li>
<li><a href="#selected-scenarios"><span class="toc-section-number">4.3</span> Selected scenarios</a><ul>
<li><a href="#shared-protocol"><span class="toc-section-number">4.3.1</span> Shared protocol</a></li>
<li><a href="#default-setup"><span class="toc-section-number">4.3.2</span> Default setup</a></li>
<li><a href="#window-of-1"><span class="toc-section-number">4.3.3</span> Window of 1</a></li>
<li><a href="#large-difference-between-contributions"><span class="toc-section-number">4.3.4</span> Large difference between contributions</a></li>
<li><a href="#background-noise"><span class="toc-section-number">4.3.5</span> Background noise</a></li>
<li><a href="#interdependent-events"><span class="toc-section-number">4.3.6</span> Interdependent events</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion"><span class="toc-section-number">5</span> Conclusion</a></li>
</ul>
</nav>
<!-- toc -->
<p>Given events occurring along a discrete timeline, the goal is to determine the effect of each event kind. The observable is a real-valued signal <span class="math inline">\(\phi\)</span> which is assumed to be a sum of the effects of recent events. The effects of any event are assumed negligible past a certain delay <span class="math inline">\(w\)</span>.</p>
<p>The solution consists in adjusting the contributions of each event to the signal knowing which events occurred recently from <span class="math inline">\(t-w+1\)</span> to <span class="math inline">\(t\)</span> and the latest value of the signal, <span class="math inline">\(\phi(t)\)</span>. The original predicted contributions are corrected so as to predict <span class="math inline">\(\phi(t)\)</span> perfectly by absorbing a share of the difference with the predicted signal <span class="math inline">\(\hat{\phi}(t)\)</span>. Each share is determined roughly by the recent standard deviation of the contribution, allowing the predictions of stable contributions to eventually converge, regardless of fluctuations in other contributions.</p>
<p>A valuable property of this system is that only resources corresponding to active events are involved, as opposed to systems in which all the nodes are updated at every time step.</p>
<h1 id="motivation-in-the-context-of-artificial-general-intelligence"><span class="header-section-number">1</span> Motivation in the context of artificial general intelligence</h1>
<p>The problem we are trying to solve arises while developing a cognitive system that operates in real-time and is driven by a single goal function. In this context, a goal function <span class="math inline">\(\phi\)</span> is a real-valued signal over discrete time, whose value becomes available at each time step. It represents how well the system is doing, i.e. it would combine rewards and penalties. Some of these rewards and penalties may correspond to direct interactions of the system with its environment, such as acquiring food or losing energy. Other rewards and penalties may be generated internally by the system itself, as a way to encourage itself to pursue certain paths.</p>
<p>In such a cognitive system, there is a finite (but possibly growing) collection of possible actions. Each action can be viewed as a button. We call an act an instance of an action, i.e. the press of a button. An act is a pair (action, instant). An action, naturally can correspond to a modification of the system in its environment, such as an attempt to move forward. It can also directly feed back into the system’s input ports without directly affecting the environment. No matter what kind of action is triggered, it takes some amount of time to have an effect on the goal function. Here and throughout this paper, we assume that most meaningful effects of an action occur within a given time window, which can be a short as 5 steps. We choose this window roughly to capture reactions of the system to its own decisions, so it has enough time to “realize” what it just did and produce a self-reward or a self-penalty. Longer-term effects of course exist and will have to be dealt with differently.</p>
<p>Given such a goal function <span class="math inline">\(\phi\)</span> and the knowledge of which actions were triggered within a time window of length <span class="math inline">\(w\)</span>, we wish to determine the impact of each action on <span class="math inline">\(\phi\)</span>.</p>
<h1 id="general-design-contraints"><span class="header-section-number">2</span> General design contraints</h1>
<h2 id="independence-from-context"><span class="header-section-number">2.1</span> Independence from context</h2>
<p>The response to an action is considered the same independently from the context. In the case of artificial general intelligence (AGI), this is generally not the case. However, it is possible to create as many controls (“buttons”) as there are contexts. Instead of studying the response to an action regardless of the context, we can study the response to the pair (context, action).</p>
<h2 id="effects-can-be-delayed"><span class="header-section-number">2.2</span> Effects can be delayed</h2>
<p>We wish to capture the “immediate” effects of an action. However, our system is such that during a time step it can only propagate information from one node to another. It take normally several steps for some input information to reach the nodes in charge of triggering actions.</p>
<p>So, while we are only interested in the immediate effects of actions, we need to leave sufficient time for the system to react to such effects.</p>
<h2 id="overlapping-effects"><span class="header-section-number">2.3</span> Overlapping effects</h2>
<p>Multiple actions can take place simultaneously, or close enough that their effects on the goal function overlap. Our main challenge is to decompose the signal into a combination of responses from multiple recent actions.</p>
<p>The simplest approach is to model <span class="math inline">\(\phi\)</span> as a sum of responses to actions, and this is the one we’ll follow.</p>
<h2 id="incremental-learning"><span class="header-section-number">2.4</span> Incremental learning</h2>
<p>It should be possible to start inferring the effects of new actions when they start appearing. If only one action is new and the effects of all the other actions are already well known, no relearning should be necessary, and learning the effects of the new action should be as fast as if it were the only action.</p>
<h2 id="adaptation"><span class="header-section-number">2.5</span> Adaptation</h2>
<p>If the effects of actions change progressively over time, the system should be able to adapt. The adaptation rate should not slow down as the system ages.</p>
<h1 id="notations"><span class="header-section-number">3</span> Notations</h1>
<p>Our approach doesn’t require the notion of goal function or actions. We’ll simply refer to the goal function <span class="math inline">\(\phi\)</span> as the <strong>signal</strong>. Each act is an action occurring at a given time and will be called an <strong>event</strong>. The action is the <strong>kind</strong> of the event.</p>
<p>The variable <span class="math inline">\(k\)</span> will be used typically to identify each event uniquely among the set of events <span class="math inline">\(K\)</span>.</p>
<p>Each event is a pair <span class="math inline">\((E_k, t_k)\)</span> of the kind <span class="math inline">\(E_k\)</span> and of the instant <span class="math inline">\(t_k\)</span> at which it occurred.</p>
<p>An event kind is associated with a function that represents its linear contribution to <span class="math inline">\(\phi\)</span>. We’ll denote <span class="math inline">\(E_k(\tau)\)</span> the value of this function at <span class="math inline">\(\tau\)</span>, where <span class="math inline">\(\tau\)</span> is the time elapsed since the occurrence of an event of this kind. Naturally, the event has no contribution to <span class="math inline">\(\phi\)</span> before it occurs, so we have:</p>
<p><span class="math display">\[
\forall k \in K: \forall \tau &lt; 0: E_k(\tau) = 0
\]</span></p>
<p>Additionally, our model assumes that the effect of any event doesn’t last longer than <span class="math inline">\(w\)</span>, called <strong>window</strong> length or just window:</p>
<p><span class="math display">\[
\forall k \in K: \forall \tau \ge w: E_k(\tau) = 0
\]</span></p>
<p>The only interesting values of <span class="math inline">\(E_k\)</span> are the <span class="math inline">\(w\)</span> values <span class="math inline">\(E_k(0), E_k(1), \dots, E_k(w-1)\)</span>. These are the values that our algorithm will try to determine, for each event kind <span class="math inline">\(k \in K\)</span>.</p>
<p>The signal <span class="math inline">\(\phi\)</span> is modeled as the sum of the effects of all events, i.e.</p>
<p><span class="math display">\[
\phi: t \rightarrow \sum_{k \in K} E_k(t-t_k)
\]</span></p>
<p>Given the properties of <span class="math inline">\(E_k\)</span> mentioned above, all events occurring outside the window (<span class="math inline">\(t_k \notin [t - w + 1, t]\)</span>) can be ignored in the prediction of <span class="math inline">\(\phi(t)\)</span>, denoted <span class="math inline">\(\hat{\phi}(t)\)</span>.</p>
<p>In general, a hat <span class="math inline">\(\hat{}\)</span> on a variable denotes a prediction of this variable.</p>
<p>Since estimators have a state that changes over time, we use a parenthesized superscript to specify which state we’re referring to. In the following example, we use the variable <span class="math inline">\(\hat{\mu}\)</span> to represent the exponential moving average of the sequence <span class="math inline">\(x\)</span>. <span class="math inline">\(\hat{\mu}\)</span> is updated as follows:</p>
<p><span class="math display">\[
\hat{\mu}^{(t+1)} = r x_t + (1-r) \hat{\mu}^{(t)}
\]</span></p>
<p>which could be implemented as the in-place assignment</p>
<p><span class="math display">\[
\hat{\mu} \leftarrow r x_t + (1-r) \hat{\mu}
\]</span></p>
<h1 id="solution"><span class="header-section-number">4</span> Solution</h1>
<h2 id="outline"><span class="header-section-number">4.1</span> Outline</h2>
<p>Informally, the solution consists in maintaining for each event kind a number that represents the expected effect of this action after some delay. Multiple event of different types can take place simultaneously, each with an expected effect which is a contribution to the signal at some future instant <span class="math inline">\(t\)</span>. The expected value of the signal is the sum of the contributions at <span class="math inline">\(t\)</span> of the recent events. The observed value of the signal is used to correct the expected contributions into what each contribution should have been. The contributions are not corrected evenly, but according to a weight proportional to the standard deviation of the contribution. In other words, the more a contribution fluctuates, the more it is prone to being corrected. Conversely, a contribution that fluctuates less will receive a smaller correction relative to the other co-occurring contributions.</p>
<h2 id="description"><span class="header-section-number">4.2</span> Description</h2>
<h3 id="prediction-and-update"><span class="header-section-number">4.2.1</span> Prediction and update</h3>
<p>At each step <span class="math inline">\(t\)</span> of the computation, the value of the signal is observed and denoted <span class="math inline">\(\phi(t)\)</span>.</p>
<p>All the events that occurred within the last <span class="math inline">\(w\)</span> steps are assumed to contribute to the signal. The predicted signal at instant <span class="math inline">\(t\)</span> is denoted <span class="math inline">\(\hat{\phi}(t)\)</span> and is computed as follows:</p>
<p><span class="math display">\[
\hat{\phi}(t) = \sum_{\{ k \in K | t_k \in [t-w+1, t] \}}
                   \hat{E}_k^{(t)}(t-t_k)
\]</span></p>
<p>As soon as <span class="math inline">\(\phi(t)\)</span> is known, each predicted term <span class="math inline">\(\hat{E}_k^{(t)}(t-t_k)\)</span> is corrected so as to add up to the observed <span class="math inline">\(\phi(t)\)</span>:</p>
<p><span class="math display">\[
\phi(t) = \sum_{\{ k \in K | t_k \in [t-w+1, t] \}} \hat{E}^{(t+1)}(t-t_k)
\]</span></p>
<p>The difference between the prediction and the actual signal is denoted <span class="math inline">\(\delta\)</span>:</p>
<p><span class="math display">\[
\delta_t = \hat{\phi}(t) - \phi(t)
\]</span></p>
<p>The terms are corrected by receiving each a share of <span class="math inline">\(\delta_t\)</span>:</p>
<p><span class="math display">\[
\hat{E}^{(t+1)}(t-t_k) = \hat{E}^{(t)}(t-t_k) - v_k^{(t)}(t-t_k) \delta_k
\]</span></p>
<p>where each weight <span class="math inline">\(v_k^{(t)}(t-t_k)\)</span> is nonnegative. All weights at instant <span class="math inline">\(t\)</span> add up to 1. They are determined so as to reflect the uncertainty on each contributing term, and so that the terms predicted consistently with high certainty will be corrected by a small amount while the more uncertain terms will be corrected by a greater amount. An estimation of the standard deviation of each term is used for this purpose:</p>
<p><span class="math display">\[
v_k^{(t)}(t-t_k) = \frac{ \hat{\sigma}_k^{(t)}(t-t_k) }
                        { \sum_{\{ k \in K | t_k \in [t-w+1, t] \}}
                            \hat{\sigma}_k^{(t)}(t-t_k) }
\]</span></p>
<p>where <span class="math inline">\(\hat{\sigma}_k^{(t)}(t-t_k)\)</span> is an estimate of the standard deviation of <span class="math inline">\(\hat{E}_k\)</span> based on the earlier known values of <span class="math inline">\(\hat{E}_k\)</span>.</p>
<p>Note that standard deviations are estimated using exponential smoothing because of their simplicity and low memory requirements, but other methods should work well too. Until a certain number of samples is reached, they behave like the classic sample mean and sample standard deviation estimators. Beyond that short initial phase, they give more weight to recent values.</p>
<h3 id="details-and-refinements"><span class="header-section-number">4.2.2</span> Details and refinements</h3>
<p>There are two classes of special cases where the standard deviation cannot be used to determine the weight:</p>
<ol type="1">
<li>In the presence of fewer than 2 samples, the sample standard deviation is undefined.</li>
<li>If the initial samples are all equal, the estimated standard deviation is 0, which results in <span class="math inline">\(\hat{E}_k\)</span> being not updated ever again.</li>
</ol>
<p>For special case (1), a possible trick is to pretend the standard deviation is so large that all the other weights are negligible, except those in the similar situation with an undefined standard deviation. Given <span class="math inline">\(n\)</span> such problematic terms, we can assign them each a weight of <span class="math inline">\(1/n\)</span>, and assign a weight of <span class="math inline">\(0\)</span> to the terms whose standard deviation is defined.</p>
<p>For special case (2), we can impose a minimum share to each term, even if the standard deviation is zero.</p>
<p>Additionally, we observed that with noisy background noise, non-noisy terms converge much faster if the weights are not exactly proportional to the standard deviations, but if we slightly amplify the top weights.</p>
<p>The final recipe for obtaining the weights consists in the following:</p>
<ol type="1">
<li>Express the standard deviations relative to the maximum standard deviation among all the terms, denoted <span class="math inline">\(r_k\)</span> for term <span class="math inline">\(k\)</span>.</li>
<li>Transform each <span class="math inline">\(r_k\)</span> into <span class="math inline">\(f(r_k)\)</span> to favor larger values and avoid null weights, using for example <span class="math inline">\(f : x \rightarrow \max(0.001, 0.5 x^{1.3} + 0.5 x)\)</span>, then normalize them such that they add up to 1.</li>
</ol>
<h2 id="selected-scenarios"><span class="header-section-number">4.3</span> Selected scenarios</h2>
<p>A series of tests was conducted to evaluate the behavior of the system with different parameters and under different conditions.</p>
<p>The source code is currently available at <a href="https://github.com/mjambon/unitron">https://github.com/mjambon/unitron</a>, commit <code>c725d8dd</code>.</p>
<h3 id="shared-protocol"><span class="header-section-number">4.3.1</span> Shared protocol</h3>
<p>A single run starts from time <span class="math inline">\(t=0\)</span> and runs as many steps as necessary to reach specified conditions. This number of steps <span class="math inline">\(T\)</span> will be our main criterion for determining how well the system performs.</p>
<p>These runs being non-deterministic, we repeat them 100 times, and report simple statistics on the value of <span class="math inline">\(N\)</span> in each case.</p>
<p>The default setup consists in the following:</p>
<ul>
<li>Two actions <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> may be fired at each time step, with probabilities <span class="math inline">\(P(A) = 0.5\)</span> and <span class="math inline">\(P(B) = 0.5\)</span>.</li>
<li>Each action has an additive effect on the goal function. By default, A and B have effects on the value of the goal function for the current step and the next two steps. The contributions of <span class="math inline">\(A\)</span> are <span class="math inline">\(E_A = [1, -0.5, 0.25, 0, \dots]\)</span> and the contributions of <span class="math inline">\(B\)</span> are <span class="math inline">\(E_B = [0.1, 0.2, 0.05, 0, \dots]\)</span>.</li>
<li>The window length <span class="math inline">\(w\)</span> is 5.</li>
</ul>
<p>For example, if action <span class="math inline">\(A\)</span> is triggered at some step <span class="math inline">\(t\)</span> and action <span class="math inline">\(B\)</span> is triggered at <span class="math inline">\(t+1\)</span>, and no action took place earlier and no action takes place after that, the values of the goal function <span class="math inline">\(\phi\)</span> are: <span class="math display">\[
\begin{eqnarray}
\dots &amp;&amp; \\
\phi(t-1) &amp;=&amp; 0\\
\phi(t)   &amp;=&amp; 1 \\
\phi(t+1) &amp;=&amp; -0.5 + 0.1 \\
\phi(t+2) &amp;=&amp; 0.25 + 0.2 \\
\phi(t+3) &amp;=&amp; 0.05\\
\phi(t+4) &amp;=&amp; 0\\
\dots &amp;&amp;
\end{eqnarray}
\]</span></p>
<p>We’ll predict the values of <span class="math inline">\(E_A\)</span> and <span class="math inline">\(E_B\)</span> and look at how many steps it takes converge to the expected values <span class="math inline">\(E_A(0)\)</span> and <span class="math inline">\(E_B(0)\)</span>. The convergence criteria are the following:</p>
<p><span class="math display">\[
\mathrm{Condition}_A:
\left| \hat{E}_A^{(T)}(0) - E_A(0) \right| \le \epsilon_A
\]</span></p>
<p><span class="math display">\[
\mathrm{Condition}_B:
\left| \hat{E}_B^{(T)}(0) - E_B(0) \right| \le \epsilon_B
\]</span></p>
<p>with the following default error thresholds:</p>
<p><span class="math display">\[
\begin{eqnarray}
\epsilon_A &amp;=&amp; 0.05 \\
\epsilon_B &amp;=&amp; 0.005
\end{eqnarray}
\]</span></p>
<p>We assume convergence if a given condition remains valid for a large number (1000) of consecutive steps.</p>
<h3 id="default-setup"><span class="header-section-number">4.3.2</span> Default setup</h3>
<p>This setup uses only the default parameters described in the previous section. Number of steps to converge to Condition<span class="math inline">\(_{A}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 19.1 \dots 147.2\\
\mathrm{median} &amp;=&amp; 70.0\\
\hat{\mu} &amp;=&amp; 73.7\\
\hat{\sigma} &amp;=&amp; 48.9\\
\end{eqnarray}
\]</span></p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{B}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 95.8 \dots 231.3\\
\mathrm{median} &amp;=&amp; 149.0\\
\hat{\mu} &amp;=&amp; 156.1\\
\hat{\sigma} &amp;=&amp; 53.7\\
\end{eqnarray}
\]</span></p>
<h3 id="window-of-1"><span class="header-section-number">4.3.3</span> Window of 1</h3>
<p>In this setup, each action only has an immediate effect <span class="math inline">\(E_A(0)\)</span> or <span class="math inline">\(E_B(0)\)</span> and no delayed effect (<span class="math inline">\(E_A(1)\)</span>, <span class="math inline">\(E_B(1)\)</span>, etc.).</p>
<p>Additionally, the window length <span class="math inline">\(w\)</span> is 1, which is the smallest useful window possible. This results in very fast convergence as shown below.</p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{A}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 1.0 \dots 9.0\\
\mathrm{median} &amp;=&amp; 3.0\\
\hat{\mu} &amp;=&amp; 4.6\\
\hat{\sigma} &amp;=&amp; 4.1\\
\end{eqnarray}
\]</span></p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{B}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 1.0 \dots 12.0\\
\mathrm{median} &amp;=&amp; 4.0\\
\hat{\mu} &amp;=&amp; 5.5\\
\hat{\sigma} &amp;=&amp; 5.5\\
\end{eqnarray}
\]</span></p>
<h3 id="large-difference-between-contributions"><span class="header-section-number">4.3.4</span> Large difference between contributions</h3>
<p>In this setup, <span class="math inline">\(E_A(0)\)</span> is 100 instead of 1, while <span class="math inline">\(E_B(0)\)</span> remains 0.1.</p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{A}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 49.6 \dots 353.0\\
\mathrm{median} &amp;=&amp; 235.0\\
\hat{\mu} &amp;=&amp; 215.3\\
\hat{\sigma} &amp;=&amp; 118.3\\
\end{eqnarray}
\]</span></p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{B}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 141.4 \dots 455.5\\
\mathrm{median} &amp;=&amp; 303.0\\
\hat{\mu} &amp;=&amp; 300.2\\
\hat{\sigma} &amp;=&amp; 120.1\\
\end{eqnarray}
\]</span></p>
<p>It takes 2-4 times longer to converge in this setup than in the default setup. A crude explanation is that the relative error tolerance is now smaller, since <span class="math inline">\(\epsilon_A\)</span> and <span class="math inline">\(\epsilon_B\)</span> are unchanged but the gap between extreme values has increased.</p>
<h3 id="background-noise"><span class="header-section-number">4.3.5</span> Background noise</h3>
<p>In this setup, we study the effects of permanent background noise on the determination of constant contribution <span class="math inline">\(E_A(0)\)</span>.</p>
<p>In order to produce noise, each event <span class="math inline">\(B\)</span> is set to occur at each time step (<span class="math inline">\(P(B)=1\)</span>) and its effects are shifted by the same random number following a centered normal distribution of parameter <span class="math inline">\(\sigma=0.5\)</span>. The control uses no noise, i.e. <span class="math inline">\(\sigma=0\)</span>.</p>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span> (control):</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 26.7 \dots 179.2\\
\mathrm{median} &amp;=&amp; 92.0\\
\hat{\mu} &amp;=&amp; 97.3\\
\hat{\sigma} &amp;=&amp; 66.6\\
\end{eqnarray}
\]</span></p>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span> (background noise):</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 484.8 \dots 4706.0\\
\mathrm{median} &amp;=&amp; 1108.0\\
\hat{\mu} &amp;=&amp; 2113.4\\
\hat{\sigma} &amp;=&amp; 1940.1\\
\end{eqnarray}
\]</span></p>
<p>This shows that convergence toward <span class="math inline">\(E_A(0)\)</span> is slower in the presence of background noise but nonetheless happens reliably.</p>
<h3 id="interdependent-events"><span class="header-section-number">4.3.6</span> Interdependent events</h3>
<p>In this setup, event <span class="math inline">\(A\)</span> occurs with a probability of 0.5 only if <span class="math inline">\(B\)</span> occurs too. <span class="math inline">\(A\)</span> never occurs alone:</p>
<p><span class="math display">\[\begin{eqnarray}
P(B) &amp;=&amp; 0.5 \\
P(A|B) &amp;=&amp; 0.5 \\
P(A|\neg B) &amp;=&amp; 0
\end{eqnarray}\]</span></p>
<p>The results are similar to the default setup in which <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent.</p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{A}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 4.8 \dots 168.3\\
\mathrm{median} &amp;=&amp; 73.5\\
\hat{\mu} &amp;=&amp; 82.4\\
\hat{\sigma} &amp;=&amp; 64.7\\
\end{eqnarray}
\]</span></p>
<p>Number of steps to converge to Condition<span class="math inline">\(_{B}\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
\mathrm{10^{th} \dots 90^{th}\ percentile} &amp;=&amp; 90.3 \dots 297.9\\
\mathrm{median} &amp;=&amp; 178.5\\
\hat{\mu} &amp;=&amp; 187.5\\
\hat{\sigma} &amp;=&amp; 87.8\\
\end{eqnarray}
\]</span></p>
<h1 id="conclusion"><span class="header-section-number">5</span> Conclusion</h1>
<p>It works fine but convergence is particularly fast with a window of length 1 and applications should probably try to take advantage of this.</p>
<p class="menu footer">
  <a href="https://twitter.com/mjambon">@mjambon</a> 2017-07-02<br/>
  <a href="/">Index</a>
</p>
</body>
</html>
