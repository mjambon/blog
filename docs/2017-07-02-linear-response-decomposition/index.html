<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Martin Jambon">
  <title>Real-time decomposition of a signal into a sum of responses to labeled events</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../blog.css">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <meta name=viewport content="width=device-width, initial-scale=1">
</head>
<body>
<header>
<h1 class="title">Real-time decomposition of a signal into a sum of responses to labeled events</h1>
<h2 class="author">Martin Jambon</h2>
<h3 class="date">July 2017</h3>
</header>
<nav id="TOC">
<ul>
<li><a href="#motivation-in-the-context-of-artificial-general-intelligence"><span class="toc-section-number">1</span> Motivation in the context of artificial general intelligence</a></li>
<li><a href="#general-design-contraints"><span class="toc-section-number">2</span> General design contraints</a><ul>
<li><a href="#independence-from-context"><span class="toc-section-number">2.1</span> Independence from context</a></li>
<li><a href="#effects-can-be-delayed"><span class="toc-section-number">2.2</span> Effects can be delayed</a></li>
<li><a href="#overlapping-effects"><span class="toc-section-number">2.3</span> Overlapping effects</a></li>
<li><a href="#incremental-learning"><span class="toc-section-number">2.4</span> Incremental learning</a></li>
<li><a href="#adaptation"><span class="toc-section-number">2.5</span> Adaptation</a></li>
</ul></li>
<li><a href="#notations"><span class="toc-section-number">3</span> Notations</a></li>
<li><a href="#solution"><span class="toc-section-number">4</span> Solution</a><ul>
<li><a href="#outline"><span class="toc-section-number">4.1</span> Outline</a></li>
<li><a href="#description"><span class="toc-section-number">4.2</span> Description</a></li>
<li><a href="#selected-scenarios"><span class="toc-section-number">4.3</span> Selected scenarios</a><ul>
<li><a href="#shared-protocol"><span class="toc-section-number">4.3.1</span> Shared protocol</a></li>
<li><a href="#default-setup"><span class="toc-section-number">4.3.2</span> Default setup</a></li>
<li><a href="#large-difference-between-contributions"><span class="toc-section-number">4.3.3</span> Large difference between contributions</a></li>
<li><a href="#noisy-effects"><span class="toc-section-number">4.3.4</span> Noisy effects</a></li>
<li><a href="#background-noise"><span class="toc-section-number">4.3.5</span> Background noise</a></li>
<li><a href="#interdependent-events"><span class="toc-section-number">4.3.6</span> Interdependent events</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion"><span class="toc-section-number">5</span> Conclusion</a></li>
<li><a href="#appendix"><span class="toc-section-number">6</span> Appendix</a><ul>
<li><a href="#exponential-moving-average-and-variance"><span class="toc-section-number">6.1</span> Exponential moving average and variance</a></li>
</ul></li>
</ul>
</nav>
<!-- toc -->
<!-- abstract -->
<h1 id="motivation-in-the-context-of-artificial-general-intelligence"><span class="header-section-number">1</span> Motivation in the context of artificial general intelligence</h1>
<p>The problem we are trying to solve arises while developing a cognitive system driven that operates in real-time and is driven by a single goal function. In this context, a goal function <span class="math inline">\(\phi\)</span> is a real-valued signal over discrete time, whose value becomes available at each time step. It represents how well the system is doing, i.e. it would combine rewards and penalties. Some of these rewards and penalties may correspond to direct interactions of the system with its environment, such as acquiring food or losing energy. Other rewards and penalties may be generated internally by the system itself, as a way to encourage itself to pursue certain paths.</p>
<p>In such a cognitive system, there is a finite (but possibly growing) collection of possible actions. Each action can be viewed as a button. We call an act an instance of an action, i.e. the press of a button. An act is a pair (action, instant). An action, naturally can correspond to a modification of the system in its environment, such as an attempt to move forward. It can also directly feed back into the system's input ports without directly affecting the environment. No matter what kind of action is triggered, it takes some amount of time to have an effect on the goal function. Here and throughout this paper, we assume that most meaningful effects of an action occur within a given time window, which can be a short as 10 steps. We choose this window roughly to capture reactions of the system to its own decisions, so it has enough time to &quot;realize&quot; what it just did and produce a self-reward or a self-penalty. Longer-term effects of course exist and will have to be dealt with differently.</p>
<p>Given such a goal function <span class="math inline">\(\phi\)</span> and the knowledge of which actions were triggered within a time window of length <span class="math inline">\(w\)</span>, we wish to determine the impact of each action on <span class="math inline">\(\phi\)</span>.</p>
<h1 id="general-design-contraints"><span class="header-section-number">2</span> General design contraints</h1>
<h2 id="independence-from-context"><span class="header-section-number">2.1</span> Independence from context</h2>
<p>The response to an action is considered the same independently from the context. In the case of artificial general intelligence (AGI), this is generally not the case. However, it is possible to create as many controls (&quot;buttons&quot;) as there are contexts. Instead of studying the response to an action regardless of the context, we can study the response to the pair (context, action).</p>
<h2 id="effects-can-be-delayed"><span class="header-section-number">2.2</span> Effects can be delayed</h2>
<p>We wish to capture the &quot;immediate&quot; effects of an action. However, our system is such that during a time step it can only propagate information from one node to another. It is not organized into layers, typically several steps are required for some input information to reach the nodes in charge of triggering actions.</p>
<p>So, while we are only interested in the immediate effects of actions, we need to leave sufficient time for the system to react to such effects.</p>
<h2 id="overlapping-effects"><span class="header-section-number">2.3</span> Overlapping effects</h2>
<p>Multiple actions can take place simultaneously, or close enough that their effects on the goal function overlap. Our main challenge is to decompose the signal into a combination of responses from multiple recent actions.</p>
<p>The simplest approach is to model <span class="math inline">\(\phi\)</span> as a sum of responses to actions, and this is the one we'll follow.</p>
<h2 id="incremental-learning"><span class="header-section-number">2.4</span> Incremental learning</h2>
<p>It should be possible to start inferring the effects of new actions when they start appearing. If only one action is new and the effects of all the other actions are already well known, no relearning should be necessary, and learning the effects of the new action should be as fast as if it were the only action.</p>
<h2 id="adaptation"><span class="header-section-number">2.5</span> Adaptation</h2>
<p>If the effects of actions change progressively over time, the system should be able to adapt. The adaptation rate should not slow down as the system ages.</p>
<h1 id="notations"><span class="header-section-number">3</span> Notations</h1>
<p>Our approach doesn't require the notion of goal function or actions. We'll simply refer to the goal function <span class="math inline">\(\phi\)</span> as the <strong>signal</strong>. Each act is an action occurring at a given time and will be called an <strong>event</strong>. The action is the <strong>kind</strong> of the event.</p>
<p>The variable <span class="math inline">\(k\)</span> will be used typically to identify each event uniquely among the set of events <span class="math inline">\(K\)</span>.</p>
<p>Each event is a pair <span class="math inline">\((E_k, t_k)\)</span> of the kind <span class="math inline">\(E_k\)</span> and of the instant <span class="math inline">\(t_k\)</span> at which it occurred.</p>
<p>An event kind is associated with a function that represents its linear contribution to <span class="math inline">\(\phi\)</span>. We'll denote <span class="math inline">\(E_k(\tau)\)</span> the value of this function at <span class="math inline">\(\tau\)</span>, where <span class="math inline">\(\tau\)</span> is the time elapsed since the occurrence of an event of this kind. Naturally, the event has no contribution to <span class="math inline">\(\phi\)</span> before it occurs, so we have:</p>
<p><span class="math display">\[
\forall k \in K: \forall \tau &lt; 0: E_k(\tau) = 0
\]</span></p>
<p>Additionally, our model assumes that the effect of any event doesn't last longer than <span class="math inline">\(w\)</span>, called <strong>window</strong> length or just window:</p>
<p><span class="math display">\[
\forall k \in K: \forall \tau \ge w: E_k(\tau) = 0
\]</span></p>
<p>The only interesting values of <span class="math inline">\(E_k\)</span> are the <span class="math inline">\(w\)</span> values <span class="math inline">\(E_k(0), E_k(1), \dots, E_k(w-1)\)</span>. These are the values that our algorithm will try to determine, for each event kind <span class="math inline">\(k \in K\)</span>.</p>
<p>The signal <span class="math inline">\(\phi\)</span> is modeled as the sum of the effects of all events, i.e.</p>
<p><span class="math display">\[
\phi: t \rightarrow \sum_{k \in K} E_k(t-t_k)
\]</span></p>
<p>Given the properties of <span class="math inline">\(E_k\)</span> mentioned above, all events occurring outside the window (<span class="math inline">\(t_k \notin [t - w + 1, t]\)</span>) can be ignored in the computation of <span class="math inline">\(\phi(t)\)</span>.</p>
<p>Estimated or predicted equivalents of a variable are denoted with a hat. For example, <span class="math inline">\(\hat{\phi}(t)\)</span> is the predicted value of <span class="math inline">\(\phi(t)\)</span>.</p>
<p>Since estimators have a state that changes over time, we use a parenthesized superscript to specify which state we're referring to. In the following example, we use the variable <span class="math inline">\(\hat{\mu}\)</span> to represent the exponential moving average of the sequence <span class="math inline">\(x\)</span>. <span class="math inline">\(\hat{\mu}\)</span> is updated as follows:</p>
<p><span class="math display">\[
\hat{\mu}^{(t+1)} = r x_t + (1-r) \hat{\mu}^{(t)}
\]</span></p>
<p>which could be implemented as the in-place assignment</p>
<p><span class="math display">\[
\hat{\mu} \leftarrow r x_t + (1-r) \hat{\mu}
\]</span></p>
<h1 id="solution"><span class="header-section-number">4</span> Solution</h1>
<h2 id="outline"><span class="header-section-number">4.1</span> Outline</h2>
<p>Informally, the solution consists in maintaining for each action a number that represents the expected effect of this action after some delay. Multiple actions take place, each with an expected effect which is a contribution to the signal at some future instant <span class="math inline">\(t\)</span>. The expected value of the signal is the sum of the contributions at <span class="math inline">\(t\)</span> of the previous actions. The observed value of the signal is used to correct the expected contributions into what each contribution should have been. The contributions are not corrected evenly, but according to a weight proportional to the standard deviation of the contribution. In other words, the more a contribution fluctuates, the more it is prone to being corrected. Conversely, a contribution that fluctuates less will receive a smaller correction relative to the other co-occurring contributions.</p>
<h2 id="description"><span class="header-section-number">4.2</span> Description</h2>
<p>At each step <span class="math inline">\(t\)</span> of the computation, the value of the signal is observed and denoted <span class="math inline">\(\phi(t)\)</span>.</p>
<p>All the events that occurred within the last <span class="math inline">\(w\)</span> steps are assumed to contribute to the signal. The predicted signal at instant <span class="math inline">\(t\)</span> is denoted as <span class="math inline">\(\hat{\phi}(t)\)</span> and is computed as follows:</p>
<p><span class="math display">\[
\hat{\phi}(t) = \sum_{\{ k \in K | t_k \in [t-w+1, t] \}}
                   \hat{E}_k^{(t)}(t-t_k)
\]</span></p>
<p>The difference between the prediction and the actual signal is denoted <span class="math inline">\(\delta\)</span>:</p>
<p><span class="math display">\[
\delta_t = \hat{\phi}(t) - \phi(t)
\]</span></p>
<p>Each predicted term <span class="math inline">\(\hat{E}_k^{(t)}(t-t_k)\)</span> is an average of the previous values of <span class="math inline">\(\tilde{E}_k\)</span>, which are the corrected terms. These corrected terms are defined such that at a given time <span class="math inline">\(t\)</span>, they add up to the observed signal <span class="math inline">\(\phi(t)\)</span>:</p>
<p><span class="math display">\[
\phi(t) = \sum_{\{ k \in K | t_k \in [t-w+1, t] \}} \tilde{E}^{(t)}(t-t_k)
\]</span></p>
<p>Splitting <span class="math inline">\(\phi(t)\)</span> into corrected terms is done by splitting and distributing the difference <span class="math inline">\(\delta_t\)</span> over the predicted terms:</p>
<p><span class="math display">\[
\tilde{E}^{(t)}(t-t_k) = \hat{E}^{(t)}(t-t_k) - v_k^{(t)}(t-t_k) \delta_k
\]</span></p>
<p>where each weight <span class="math inline">\(v_k^{(t)}(t-t_k)\)</span> is nonnegative. All weights at instant <span class="math inline">\(t\)</span> add up to 1. They are determined so as to reflect the uncertainty on each contributing term, so that the terms predicted consistently with high certainty will be corrected by a small amount while the more uncertain terms will be corrected by a greater amount. An estimation of the standard deviation of each term is used for this purpose:</p>
<p><span class="math display">\[
v_k^{(t)}(t-t_k) = \frac{ \hat{\sigma}_k^{(t)}(t-t_k) }
                        { \sum_{\{ k \in K | t_k \in [t-w+1, t] \}}
                            \hat{\sigma}_k^{(t)}(t-t_k) }
\]</span></p>
<p>where <span class="math inline">\(\hat{\sigma}_k^{(t)}(t-t_k)\)</span> is an estimate of the standard deviation of <span class="math inline">\(\tilde{E}_k\)</span> based on the earlier known values of <span class="math inline">\(\tilde{E}_k\)</span>.</p>
<p>Note that our averages and standard deviations are estimated using exponential smoothing because of their simplicity (see appendix), but other methods should work well too. Until a certain number of samples is reached, they behave like the classic sample mean and sample standard deviation estimators. Beyond that, they give more weight to recent values.</p>
<p>There are two classes of special cases where the standard deviation cannot be used to determine the weight:</p>
<ul>
<li>Special case 1: In the presence of fewer than 2 samples, the sample standard deviation is undefined.</li>
<li>Special case 2: If the initial samples are all equal, the estimated standard deviation is 0, which results in <span class="math inline">\(\tilde{E}_k\)</span> being not updated ever again.</li>
</ul>
<p>For special case 1, a possible trick is to pretend the standard deviation is so large that all the other weights are negligible, except those in the similar situation with an undefined standard deviation. Given <span class="math inline">\(n\)</span> such problematic terms, we can assign them each a weight of <span class="math inline">\(1/n\)</span>, and assign a weight of <span class="math inline">\(0\)</span> to the terms whose standard deviation is defined.</p>
<p>For special case 2, we can impose a minimum value to the estimate of the standard deviation. Let's call <span class="math inline">\(S\)</span> the sum of the standard deviations at instant <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
S_t = \sum_{\{ k \in K | t_k \in [t-w+1, t] \}}
      \hat{\sigma}_k^{(t)}(t-t_k)
\]</span></p>
<p>If <span class="math inline">\(S_t = 0\)</span>, we give an equal weight to all the terms as for special case 1. Otherwise, let <span class="math inline">\(n\)</span> be the number of terms in the sum, i.e. the number of events within the window. We define a minimum weight <span class="math inline">\(m_t\)</span> as a small fraction of <span class="math inline">\(S_t\)</span>:</p>
<p><span class="math display">\[
m_t = \frac{\epsilon}{n} S_t
\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> is a small positive constant such as 0.001.</p>
<p>Each weight is then defined as:</p>
<p><span class="math display">\[
v_k^{(t)}(t-t_k) = \frac{ \max(m, \hat{\sigma}_k^{(t)}(t-t_k)) }
                        { \sum_{\{ k \in K | t_k \in [t-w+1, t] \}}
                            \max(m, \hat{\sigma}_k^{(t)}(t-t_k)) }
\]</span></p>
<h2 id="selected-scenarios"><span class="header-section-number">4.3</span> Selected scenarios</h2>
<p>A series of tests was conducted to evaluate the behavior of the system with different parameters and under different conditions.</p>
<p>The source code is currently available at <a href="https://github.com/mjambon/unitron" class="uri">https://github.com/mjambon/unitron</a></p>
<h3 id="shared-protocol"><span class="header-section-number">4.3.1</span> Shared protocol</h3>
<p>A single run starts from time <span class="math inline">\(t=0\)</span> and runs as many steps as necessary to reach specified conditions. This number of steps <span class="math inline">\(T\)</span> will be our main criterion for determining how well the system performs.</p>
<p>These runs being non-deterministic, we repeat them 100 times, and report simple statistics on the value of <span class="math inline">\(N\)</span> in each case.</p>
<p>The default setup consists in the following:</p>
<ul>
<li>Two actions <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> may be fired at each time step, each with a certain probability (<span class="math inline">\(P(A) = 0.5\)</span>, <span class="math inline">\(P(B) = 0.5\)</span>).</li>
<li>Each action has an additive effect on the goal function. By default, A and B have effects on the value of the goal function for the current step and the next two steps. The contributions of <span class="math inline">\(A\)</span> are <span class="math inline">\(E_A = [1, -0.5, 0.25, 0, \dots]\)</span> and the contributions of <span class="math inline">\(B\)</span> are <span class="math inline">\(E_B = [0.1, 0.2, 0.05, 0, \dots]\)</span>.</li>
<li>The window length <span class="math inline">\(w\)</span> is 10.</li>
</ul>
<p>For example, if action <span class="math inline">\(A\)</span> is triggered at some step <span class="math inline">\(t\)</span> and action <span class="math inline">\(B\)</span> is triggered at <span class="math inline">\(t+1\)</span>, and no action took place earlier and no action takes place after that, the values of the goal function <span class="math inline">\(\phi\)</span> are: <span class="math display">\[
\begin{eqnarray}
\dots &amp;&amp; \\
\phi(t-1) &amp;=&amp; 0\\
\phi(t)   &amp;=&amp; 1 \\
\phi(t+1) &amp;=&amp; -0.5 + 0.1 \\
\phi(t+2) &amp;=&amp; 0.25 + 0.2 \\
\phi(t+3) &amp;=&amp; 0.05\\
\phi(t+4) &amp;=&amp; 0\\
\dots &amp;&amp;
\end{eqnarray}
\]</span></p>
<p>We'll predict the values of <span class="math inline">\(E_A\)</span> and <span class="math inline">\(E_B\)</span> and look at how many steps it takes converge to the expected values <span class="math inline">\(E_A(0)\)</span> and <span class="math inline">\(E_B(0)\)</span>. The convergence criteria are the following:</p>
<p><span class="math display">\[
\mathrm{Condition}_A:
\left| \hat{E}_A^{(T)}(0) - E_A(0) \right| \le \epsilon_A
\]</span></p>
<p><span class="math display">\[
\mathrm{Condition}_B:
\left| \hat{E}_B^{(T)}(0) - E_B(0) \right| \le \epsilon_B
\]</span></p>
<p>with the following default error thresholds:</p>
<p><span class="math display">\[
\begin{eqnarray}
\epsilon_A &amp;=&amp; 0.05 \\
\epsilon_B &amp;=&amp; 0.005
\end{eqnarray}
\]</span></p>
<p>We assume convergence if a given condition remains valid for 100 consecutive steps.</p>
<h3 id="default-setup"><span class="header-section-number">4.3.2</span> Default setup</h3>
<p>This setup uses only the default parameters described in the previous section.</p>
<p>Number of steps to converge to Condition<span class="math inline">\(_A\)</span>:</p>
<ul>
<li>mean, standard deviation: 99.2, 50.3</li>
<li>median: 84.5</li>
<li>10th percentile: 53.0</li>
<li>90th percentile: 158.6</li>
</ul>
<p>Number of steps to converge to Condition<span class="math inline">\(_B\)</span>:</p>
<ul>
<li>mean, standard deviation: 80.8, 55.9</li>
<li>median: 71.5</li>
<li>10th percentile: 22.9</li>
<li>90th percentile: 144.0</li>
</ul>
<h3 id="large-difference-between-contributions"><span class="header-section-number">4.3.3</span> Large difference between contributions</h3>
<p>In this setup, <span class="math inline">\(E_A(0)\)</span> is 100 instead of 1, while <span class="math inline">\(E_B(0)\)</span> remains 0.1.</p>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span>:</p>
<ul>
<li>mean, standard deviation: 405.5, 179.5</li>
<li>median: 363.0</li>
<li>10th percentile: 205.5</li>
<li>90th percentile: 688.0</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_B\)</span>:</p>
<ul>
<li>mean, standard deviation: 299.1, 206.1</li>
<li>median: 313.5</li>
<li>10th percentile: 2.9</li>
<li>90th percentile: 542.1</li>
</ul>
<p>In this setup, like in the default setup, it takes roughly the same number of steps to converge to both the lower value <span class="math inline">\(E_B(0)\)</span> and the higher value <span class="math inline">\(E_A(0)\)</span>.</p>
<p>This is not surprising since nothing in the algorithm would treat values that are close to 0 differently than the value far from 0.</p>
<p>It takes however 4-5 times longer to converge in this setup. A crude explanation is that even though the tolerance with respect to deviations wasn't changed from the original setup, the gap between the contributions to predict increased. If we define the relative tolerance as the absolute tolerance (<span class="math inline">\(\epsilon_A\)</span> or <span class="math inline">\(\epsilon_B\)</span>) over the maximum difference between expected contributions, we get the following relative tolerances:</p>
<ul>
<li><span class="math inline">\(0.05/(1 - (-0.5)) = 3.3\%\)</span> in the default setup</li>
<li><span class="math inline">\(0.05/(100 - (-0.5)) = 0.050\%\)</span> in the new setup</li>
</ul>
<p>When scaling the tolerances accordingly (<span class="math inline">\(0.05\rightarrow 3.35\)</span>), the median number of steps for Condition<span class="math inline">\(_A\)</span> and Condition<span class="math inline">\(_B\)</span> become 182.5 and 154.0 respectively. So the new setup requires fewer steps but not as few as the default setup, possibly an effect caused by all contributions being clustered at or around the same value except for one.</p>
<p>Perhaps convergence tends to be faster if the contributions are more evenly spaced among each other.</p>
<h3 id="noisy-effects"><span class="header-section-number">4.3.4</span> Noisy effects</h3>
<p>In this setup, we study the effects of each event <span class="math inline">\(A\)</span> are shifted by the same random number following a centered normal distribution of parameter <span class="math inline">\(\sigma=0.5\)</span>.</p>
<p>Because we expect the contributions of <span class="math inline">\(A\)</span> to have a natural standard deviation around 0.5, we increased the stopping condition <span class="math inline">\(\mathrm{maxstdev}_A\)</span> from 0.05 to 0.5 in both the control and the subject. The control uses otherwise the same parameters as the default setup.</p>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span> (control):</p>
<ul>
<li>mean, standard deviation: 70.5, 43.2</li>
<li>median: 59.5</li>
<li>10th percentile: 34.7</li>
<li>90th percentile: 127.0</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_B\)</span> (control):</p>
<ul>
<li>mean, standard deviation: 80.0, 63.4</li>
<li>median: 67.5</li>
<li>10th percentile: 19.9</li>
<li>90th percentile: 158.3</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span> (noisy):</p>
<ul>
<li>mean, standard deviation: 68.6, 37.0</li>
<li>median: 56.5</li>
<li>10th percentile: 29.9</li>
<li>90th percentile: 126.1</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_B\)</span> (noisy):</p>
<ul>
<li>mean, standard deviation: 129.4, 133.1</li>
<li>median: 96.0</li>
<li>10th percentile: 3.0</li>
<li>90th percentile: 283.0</li>
</ul>
<p>It turns out that the convergence rate for the estimation of noisy contributions (<span class="math inline">\(E_A\)</span>) are unaffected by the fact of being noisy, but the non-noisy contributions take a little longer to converge, with large variations from one run to another.</p>
<p>This is counter-intuitive and we don't have a good explanation for it.</p>
<h3 id="background-noise"><span class="header-section-number">4.3.5</span> Background noise</h3>
<p>TODO: present results for noise stdev = 0.1, 0.5, 1</p>
<p>This setup adds to the goal function, at each step, a random value following a centered normal distribution of parameter <span class="math inline">\(\sigma=0.08\)</span>. All other parameters are set to the default values.</p>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span>:</p>
<ul>
<li>mean, standard deviation: 105.9, 65.3</li>
<li>median: 90.0</li>
<li>10th percentile: 52.0</li>
<li>90th percentile: 162.1</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_B\)</span>:</p>
<ul>
<li>mean, standard deviation: 91.3, 85.2</li>
<li>median: 67.5</li>
<li>10th percentile: 21.9</li>
<li>90th percentile: 205.8</li>
</ul>
<p>These results are similar to those obtained with the default setup, even though the standard deviation of the background noise is close to <span class="math inline">\(E_B(0)\)</span> whose value is 0.1.</p>
<h3 id="interdependent-events"><span class="header-section-number">4.3.6</span> Interdependent events</h3>
<ul>
<li>B =&gt; A</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_A\)</span>:</p>
<ul>
<li>mean, standard deviation: 115.0, 57.8</li>
<li>median: 105.0</li>
<li>10th percentile: 48.9</li>
<li>90th percentile: 202.7</li>
</ul>
<p>Number of steps to reach Condition<span class="math inline">\(_B\)</span>:</p>
<ul>
<li>mean, standard deviation: 136.0, 86.0</li>
<li>median: 124.0</li>
<li>10th percentile: 43.9</li>
<li>90th percentile: 268.2</li>
</ul>
<h1 id="conclusion"><span class="header-section-number">5</span> Conclusion</h1>
<ul>
<li>suitable for large number of actions: reinforcement only affects recent actions; small computational requirements.</li>
<li>no need to select a learning rate parameter; if the conditions are right, learning is very quick. The effects of each action can be learned at their own rate.</li>
<li>overfitting is not seen as a problem that should be solved here; (context, action) pairs with poor success or poor predictability should be avoided by the cognitive system.</li>
<li>non-linear effects cannot be handled here directly. Instead, a pattern should be identified first and act as the source for a specific action. If effect(A and B) = effect(A) + effect(B) + x, we will form a control named AB, active one step after both A and B. This now allows a linear decomposition as effect(A and B)_t = effect(A)_t + effect(B)<em>t + effect(AB)</em>(t-1) which works except for t=0.</li>
</ul>
<h1 id="appendix"><span class="header-section-number">6</span> Appendix</h1>
<h2 id="exponential-moving-average-and-variance"><span class="header-section-number">6.1</span> Exponential moving average and variance</h2>
<p>The exponential moving average <span class="math inline">\(m\)</span> of a function <span class="math inline">\(f\)</span> over nonnegative integers is defined as:</p>
<p><span class="math display">\[
m_{f, \alpha} = t \rightarrow
\left\{
\begin{array}{ll}
  f(0)                                  &amp; t = 0\\
  (1-\alpha_t) \cdot m_{f,\alpha}(t-1) + \alpha_t \cdot f(t) &amp; t &gt; 0
\end{array}
\right.
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\alpha_t = \max
\left\{
\begin{array}{l}
  \frac{1}{t + 1} \\
  \alpha
\end{array}
\right.
\]</span></p>
<p>and <span class="math inline">\(\alpha\)</span> is the user-defined parameter in the range <span class="math inline">\([0, 1]\)</span> that controls how much weight is given to recent values.</p>
<p>An exponential moving variance <span class="math inline">\(v\)</span> is defined over positive integers as an exponential moving average of the squared difference between the signal <span class="math inline">\(f\)</span> and the previous moving average of <span class="math inline">\(f\)</span>:</p>
<p><span class="math display">\[
\begin{eqnarray}
v_{f, \alpha, \alpha^\prime} &amp;=&amp; m_{g, \alpha^\prime}\\
g &amp;=&amp; t \rightarrow (f(t) - m_{f, \alpha}(t-1))^2
\end{eqnarray}
\]</span></p>
<p>Note that <span class="math inline">\(v\)</span> is not defined for <span class="math inline">\(t=0\)</span>. The moving standard deviation is defined as the square root of the moving variance.</p>
<p>The parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\alpha^\prime\)</span> may be set to identical values but this is not a requirement.</p>
<p class="menu footer">
  <a href="https://twitter.com/mjambon">@mjambon</a> 2017-07-02<br/>
  <a href="/">Index</a>
</p>
</body>
</html>
